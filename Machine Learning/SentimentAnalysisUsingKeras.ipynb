{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SentimentAnalysisUsingKeras.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sonudoo/DSA/blob/master/Machine%20Learning/SentimentAnalysisUsingKeras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QGBY3QR8uPT_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, LSTM, Embedding, Input, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "import nltk\n",
        "import string\n",
        "import re\n",
        "import numpy as np\n",
        "from google.colab import drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VkgxAWtwuiXb",
        "colab_type": "code",
        "outputId": "f6ac30d6-d027-4d3e-f8d7-a93324f05698",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qmQw1E9uukHf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Read the Word2Vec data set and parse it to vectors map\n",
        "\n",
        "words = open(\"/content/drive/My Drive/Colab Notebooks/embeddings/glove.6B.50d.txt\", \"r\", encoding=\"utf8\").read().split(\"\\n\")\n",
        "\n",
        "word_to_vec_map = {}\n",
        "word_to_index_map = {}\n",
        "\n",
        "j = 0\n",
        "for i in words:\n",
        "    l = i.split()\n",
        "    if len(l) == 0:\n",
        "        continue\n",
        "    key, val = l[0], list(map(float, l[1:]))\n",
        "    word_to_vec_map[key] = np.array(val)\n",
        "    word_to_index_map[key] = j\n",
        "    j += 1\n",
        "\n",
        "# Add a dummy blank word of all zeros\n",
        "\n",
        "word_to_vec_map[''] = np.zeros(word_to_vec_map['the'].shape)\n",
        "word_to_index_map[''] = j"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lg_n-Ju2vUif",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pos = open(\"/content/drive/My Drive/Colab Notebooks/datasets/ROTTEN_TOMATOES/rt-polarity.pos.txt\").read().split(\"\\n\")[:-1]\n",
        "neg = open(\"/content/drive/My Drive/Colab Notebooks/datasets/ROTTEN_TOMATOES/rt-polarity.neg.txt\").read().split(\"\\n\")[:-1]\n",
        "statements = pos + neg\n",
        "labels = [1 for i in range(len(pos))] + [0 for i in range(len(neg))]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_3nOX-yHKOEw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Change case to lower case\n",
        "\n",
        "statements = [statement.lower() for statement in statements]\n",
        "\n",
        "# Remove all punctuations\n",
        "\n",
        "statements = [\"\".join([' ' if y in string.punctuation else y for y in list(statement)]) for statement in statements]\n",
        "\n",
        "# Tokenize \n",
        "\n",
        "statements = [re.split('\\s+', statement) for statement in statements]\n",
        "\n",
        "# Remove all words not in words_to_vec_map\n",
        "\n",
        "statements = [[word for word in statement if word in word_to_vec_map] for statement in statements]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0CQQsEWLMg5a",
        "colab_type": "code",
        "outputId": "871af58c-8e12-42b8-aa34-9ece0ab5fcd3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Find the length of the longest statement\n",
        "\n",
        "max_len = 0\n",
        "\n",
        "for statement in statements:\n",
        "    max_len = max(max_len, len(statement))\n",
        "\n",
        "print(\"Maximum states is:\", max_len)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Maximum states is: 54\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QqTbZ9uLM-TH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Applying padding\n",
        "\n",
        "statements = [[word for word in statement] + ['' for y in range(max_len - len(statement))] for statement in statements]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NHam81abvaDY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Replace word with word index\n",
        "\n",
        "statements = [[word_to_index_map[word] for word in statement] for statement in statements]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1AP-Sc3xMZta",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = np.array(statements)\n",
        "Y_train = np.array(labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VatpuqSCv2Fo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We create an input layer. As a reminder, please note that we don't specify batch_size while specifying the input shape\n",
        "# It is assumed to be the first argument\n",
        "\n",
        "X_input = Input(shape=(max_len))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXSNpFutv4dW",
        "colab_type": "code",
        "outputId": "89a7e2cb-3e2f-43bc-997a-fd8d2c6f653c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "source": [
        "# Create an embedding layer now\n",
        "# Embedding layer will map each index (index of a word from input layer) to a vector. This vector would represent\n",
        "# the features of a word\n",
        "\n",
        "vocab_len = len(word_to_vec_map) + 1 # 1 added to fit keras embedding requirement. This is the total number of words\n",
        "embed_dimension = word_to_vec_map[\"is\"].shape[0] # This is the number of feature in vector representation of a word\n",
        "\n",
        "embedding_matrix = np.zeros((vocab_len, embed_dimension))\n",
        "\n",
        "for word in word_to_vec_map:\n",
        "    embedding_matrix[word_to_index_map[word], :] = word_to_vec_map[word]\n",
        "    \n",
        "embedding_layer = Embedding(vocab_len, embed_dimension, trainable=False)\n",
        "\n",
        "# As the layer is supposed to be non-trainable and directly be used, so we will call build() and then set_weights\n",
        "embedding_layer.build((None,))\n",
        "    \n",
        "embedding_layer.set_weights([embedding_matrix])\n",
        "\n",
        "X = embedding_layer(X_input)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "96CyM6_Mv6Dk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Now we add a LSTM layer. The hidden state size is 128. We return all the sequences. Hence output is triple dimensional\n",
        "\n",
        "X = LSTM(128, return_sequences=True)(X)\n",
        "\n",
        "# Next we add some dropout\n",
        "\n",
        "X = Dropout(rate=0.5)(X)\n",
        "\n",
        "# Add another LSTM layer. But this time we only take the output of last state\n",
        "\n",
        "X = LSTM(128)(X)\n",
        "\n",
        "# Feed the 128 dimensional vector to Dense layer\n",
        "\n",
        "X = Dense(10, activation='sigmoid')(X)\n",
        "\n",
        "# Finally get a sigmoid output from another Dense layer\n",
        "\n",
        "Y = Dense(1, activation='sigmoid')(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6DNu0D9dv72G",
        "colab_type": "code",
        "outputId": "482d0d9d-7a2b-4a18-dca2-ac0941cda62b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 471
        }
      },
      "source": [
        "# Create the model\n",
        "\n",
        "model = Model(inputs = X_input, outputs = Y)\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 54)]              0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 54, 50)            20000100  \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 54, 128)           91648     \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 54, 128)           0         \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 128)               131584    \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 10)                1290      \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 11        \n",
            "=================================================================\n",
            "Total params: 20,224,633\n",
            "Trainable params: 224,533\n",
            "Non-trainable params: 20,000,100\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68FMQpLJv9Qf",
        "colab_type": "code",
        "outputId": "8d3ea976-b2a8-4229-937d-2675d4236a8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit(X_train, Y_train, epochs=400, batch_size=8192)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 10662 samples\n",
            "Epoch 1/400\n",
            "10662/10662 [==============================] - 3s 299us/sample - loss: 0.7008 - acc: 0.5000\n",
            "Epoch 2/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.6993 - acc: 0.5000\n",
            "Epoch 3/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.6976 - acc: 0.5003\n",
            "Epoch 4/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.6951 - acc: 0.4994\n",
            "Epoch 5/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.6940 - acc: 0.5055\n",
            "Epoch 6/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.6930 - acc: 0.5120\n",
            "Epoch 7/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.6922 - acc: 0.5204\n",
            "Epoch 8/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.6911 - acc: 0.5465\n",
            "Epoch 9/400\n",
            "10662/10662 [==============================] - 2s 156us/sample - loss: 0.6856 - acc: 0.6199\n",
            "Epoch 10/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.6638 - acc: 0.6402\n",
            "Epoch 11/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.6349 - acc: 0.6574\n",
            "Epoch 12/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.6443 - acc: 0.6486\n",
            "Epoch 13/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.6477 - acc: 0.6594\n",
            "Epoch 14/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.6471 - acc: 0.6432\n",
            "Epoch 15/400\n",
            "10662/10662 [==============================] - 2s 156us/sample - loss: 0.6638 - acc: 0.6140\n",
            "Epoch 16/400\n",
            "10662/10662 [==============================] - 2s 156us/sample - loss: 0.6272 - acc: 0.6720\n",
            "Epoch 17/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.6423 - acc: 0.6756\n",
            "Epoch 18/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.6283 - acc: 0.6719\n",
            "Epoch 19/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.6373 - acc: 0.6414\n",
            "Epoch 20/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.6378 - acc: 0.6400\n",
            "Epoch 21/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.6247 - acc: 0.6724\n",
            "Epoch 22/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.6256 - acc: 0.6896\n",
            "Epoch 23/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.6173 - acc: 0.6910\n",
            "Epoch 24/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.6196 - acc: 0.6711\n",
            "Epoch 25/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.6204 - acc: 0.6660\n",
            "Epoch 26/400\n",
            "10662/10662 [==============================] - 2s 154us/sample - loss: 0.6093 - acc: 0.6871\n",
            "Epoch 27/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.6135 - acc: 0.6920\n",
            "Epoch 28/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.6042 - acc: 0.6966\n",
            "Epoch 29/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.6071 - acc: 0.6813\n",
            "Epoch 30/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.6015 - acc: 0.6897\n",
            "Epoch 31/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.5996 - acc: 0.6983\n",
            "Epoch 32/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.5940 - acc: 0.7043\n",
            "Epoch 33/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.5948 - acc: 0.6957\n",
            "Epoch 34/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.5889 - acc: 0.7034\n",
            "Epoch 35/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.5912 - acc: 0.7032\n",
            "Epoch 36/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.5840 - acc: 0.7072\n",
            "Epoch 37/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.5861 - acc: 0.7013\n",
            "Epoch 38/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.5815 - acc: 0.7088\n",
            "Epoch 39/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.5809 - acc: 0.7071\n",
            "Epoch 40/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.5792 - acc: 0.7062\n",
            "Epoch 41/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.5751 - acc: 0.7108\n",
            "Epoch 42/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.5747 - acc: 0.7122\n",
            "Epoch 43/400\n",
            "10662/10662 [==============================] - 2s 154us/sample - loss: 0.5726 - acc: 0.7116\n",
            "Epoch 44/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.5707 - acc: 0.7154\n",
            "Epoch 45/400\n",
            "10662/10662 [==============================] - 2s 154us/sample - loss: 0.5703 - acc: 0.7137\n",
            "Epoch 46/400\n",
            "10662/10662 [==============================] - 2s 154us/sample - loss: 0.5679 - acc: 0.7149\n",
            "Epoch 47/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.5651 - acc: 0.7178\n",
            "Epoch 48/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.5661 - acc: 0.7159\n",
            "Epoch 49/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.5638 - acc: 0.7179\n",
            "Epoch 50/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.5616 - acc: 0.7205\n",
            "Epoch 51/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.5617 - acc: 0.7212\n",
            "Epoch 52/400\n",
            "10662/10662 [==============================] - 2s 154us/sample - loss: 0.5591 - acc: 0.7224\n",
            "Epoch 53/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.5572 - acc: 0.7229\n",
            "Epoch 54/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.5556 - acc: 0.7244\n",
            "Epoch 55/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.5543 - acc: 0.7275\n",
            "Epoch 56/400\n",
            "10662/10662 [==============================] - 2s 156us/sample - loss: 0.5526 - acc: 0.7262\n",
            "Epoch 57/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.5535 - acc: 0.7288\n",
            "Epoch 58/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.5506 - acc: 0.7282\n",
            "Epoch 59/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.5517 - acc: 0.7274\n",
            "Epoch 60/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.5508 - acc: 0.7277\n",
            "Epoch 61/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.5469 - acc: 0.7327\n",
            "Epoch 62/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.5450 - acc: 0.7337\n",
            "Epoch 63/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.5420 - acc: 0.7354\n",
            "Epoch 64/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.5415 - acc: 0.7372\n",
            "Epoch 65/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.5372 - acc: 0.7390\n",
            "Epoch 66/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.5360 - acc: 0.7417\n",
            "Epoch 67/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.5361 - acc: 0.7400\n",
            "Epoch 68/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.5315 - acc: 0.7444\n",
            "Epoch 69/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.5312 - acc: 0.7436\n",
            "Epoch 70/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.5265 - acc: 0.7491\n",
            "Epoch 71/400\n",
            "10662/10662 [==============================] - 2s 154us/sample - loss: 0.5317 - acc: 0.7441\n",
            "Epoch 72/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.5247 - acc: 0.7487\n",
            "Epoch 73/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.5438 - acc: 0.7310\n",
            "Epoch 74/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.5279 - acc: 0.7454\n",
            "Epoch 75/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.5235 - acc: 0.7511\n",
            "Epoch 76/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.5169 - acc: 0.7563\n",
            "Epoch 77/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.5145 - acc: 0.7570\n",
            "Epoch 78/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.5139 - acc: 0.7586\n",
            "Epoch 79/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.5108 - acc: 0.7590\n",
            "Epoch 80/400\n",
            "10662/10662 [==============================] - 2s 154us/sample - loss: 0.5095 - acc: 0.7619\n",
            "Epoch 81/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.5215 - acc: 0.7483\n",
            "Epoch 82/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.5383 - acc: 0.7313\n",
            "Epoch 83/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.5354 - acc: 0.7326\n",
            "Epoch 84/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.5176 - acc: 0.7514\n",
            "Epoch 85/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.5111 - acc: 0.7578\n",
            "Epoch 86/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.5071 - acc: 0.7636\n",
            "Epoch 87/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.5066 - acc: 0.7591\n",
            "Epoch 88/400\n",
            "10662/10662 [==============================] - 2s 156us/sample - loss: 0.5062 - acc: 0.7610\n",
            "Epoch 89/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.5007 - acc: 0.7644\n",
            "Epoch 90/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.4975 - acc: 0.7711\n",
            "Epoch 91/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.4986 - acc: 0.7665\n",
            "Epoch 92/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.4948 - acc: 0.7685\n",
            "Epoch 93/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.4872 - acc: 0.7749\n",
            "Epoch 94/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.4872 - acc: 0.7757\n",
            "Epoch 95/400\n",
            "10662/10662 [==============================] - 2s 156us/sample - loss: 0.4856 - acc: 0.7773\n",
            "Epoch 96/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.4986 - acc: 0.7641\n",
            "Epoch 97/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.4842 - acc: 0.7794\n",
            "Epoch 98/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.4995 - acc: 0.7608\n",
            "Epoch 99/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.4877 - acc: 0.7756\n",
            "Epoch 100/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.4915 - acc: 0.7733\n",
            "Epoch 101/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.4912 - acc: 0.7712\n",
            "Epoch 102/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.4787 - acc: 0.7844\n",
            "Epoch 103/400\n",
            "10662/10662 [==============================] - 2s 154us/sample - loss: 0.4838 - acc: 0.7778\n",
            "Epoch 104/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.4710 - acc: 0.7886\n",
            "Epoch 105/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.4759 - acc: 0.7873\n",
            "Epoch 106/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.4744 - acc: 0.7836\n",
            "Epoch 107/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.4694 - acc: 0.7907\n",
            "Epoch 108/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.4629 - acc: 0.7964\n",
            "Epoch 109/400\n",
            "10662/10662 [==============================] - 2s 154us/sample - loss: 0.4658 - acc: 0.7917\n",
            "Epoch 110/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.4757 - acc: 0.7819\n",
            "Epoch 111/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.4826 - acc: 0.7776\n",
            "Epoch 112/400\n",
            "10662/10662 [==============================] - 2s 154us/sample - loss: 0.4739 - acc: 0.7836\n",
            "Epoch 113/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.4670 - acc: 0.7871\n",
            "Epoch 114/400\n",
            "10662/10662 [==============================] - 2s 154us/sample - loss: 0.4560 - acc: 0.7985\n",
            "Epoch 115/400\n",
            "10662/10662 [==============================] - 2s 154us/sample - loss: 0.4601 - acc: 0.7952\n",
            "Epoch 116/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.4543 - acc: 0.7999\n",
            "Epoch 117/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.4506 - acc: 0.8040\n",
            "Epoch 118/400\n",
            "10662/10662 [==============================] - 2s 156us/sample - loss: 0.4454 - acc: 0.8098\n",
            "Epoch 119/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.4454 - acc: 0.8059\n",
            "Epoch 120/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.4488 - acc: 0.8025\n",
            "Epoch 121/400\n",
            "10662/10662 [==============================] - 2s 154us/sample - loss: 0.4405 - acc: 0.8127\n",
            "Epoch 122/400\n",
            "10662/10662 [==============================] - 2s 154us/sample - loss: 0.4419 - acc: 0.8099\n",
            "Epoch 123/400\n",
            "10662/10662 [==============================] - 2s 154us/sample - loss: 0.4504 - acc: 0.8012\n",
            "Epoch 124/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.4514 - acc: 0.8034\n",
            "Epoch 125/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.4526 - acc: 0.7996\n",
            "Epoch 126/400\n",
            "10662/10662 [==============================] - 2s 154us/sample - loss: 0.4334 - acc: 0.8154\n",
            "Epoch 127/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.4277 - acc: 0.8218\n",
            "Epoch 128/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.4255 - acc: 0.8225\n",
            "Epoch 129/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.4374 - acc: 0.8113\n",
            "Epoch 130/400\n",
            "10662/10662 [==============================] - 2s 154us/sample - loss: 0.4390 - acc: 0.8112\n",
            "Epoch 131/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.4310 - acc: 0.8180\n",
            "Epoch 132/400\n",
            "10662/10662 [==============================] - 2s 156us/sample - loss: 0.4209 - acc: 0.8292\n",
            "Epoch 133/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.4264 - acc: 0.8208\n",
            "Epoch 134/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.4136 - acc: 0.8310\n",
            "Epoch 135/400\n",
            "10662/10662 [==============================] - 2s 154us/sample - loss: 0.4311 - acc: 0.8149\n",
            "Epoch 136/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.4171 - acc: 0.8249\n",
            "Epoch 137/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.4337 - acc: 0.8152\n",
            "Epoch 138/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.4100 - acc: 0.8333\n",
            "Epoch 139/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.4292 - acc: 0.8169\n",
            "Epoch 140/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.4264 - acc: 0.8164\n",
            "Epoch 141/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.4207 - acc: 0.8262\n",
            "Epoch 142/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.4195 - acc: 0.8244\n",
            "Epoch 143/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.4295 - acc: 0.8162\n",
            "Epoch 144/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.4288 - acc: 0.8171\n",
            "Epoch 145/400\n",
            "10662/10662 [==============================] - 2s 154us/sample - loss: 0.4335 - acc: 0.8165\n",
            "Epoch 146/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.4140 - acc: 0.8273\n",
            "Epoch 147/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.4073 - acc: 0.8338\n",
            "Epoch 148/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.3967 - acc: 0.8405\n",
            "Epoch 149/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.4059 - acc: 0.8331\n",
            "Epoch 150/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.4068 - acc: 0.8351\n",
            "Epoch 151/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.3921 - acc: 0.8439\n",
            "Epoch 152/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.3938 - acc: 0.8422\n",
            "Epoch 153/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.4293 - acc: 0.8153\n",
            "Epoch 154/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.4014 - acc: 0.8355\n",
            "Epoch 155/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.3859 - acc: 0.8511\n",
            "Epoch 156/400\n",
            "10662/10662 [==============================] - 2s 154us/sample - loss: 0.3842 - acc: 0.8505\n",
            "Epoch 157/400\n",
            "10662/10662 [==============================] - 2s 154us/sample - loss: 0.3784 - acc: 0.8547\n",
            "Epoch 158/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.3807 - acc: 0.8507\n",
            "Epoch 159/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.3789 - acc: 0.8528\n",
            "Epoch 160/400\n",
            "10662/10662 [==============================] - 2s 154us/sample - loss: 0.3716 - acc: 0.8585\n",
            "Epoch 161/400\n",
            "10662/10662 [==============================] - 2s 154us/sample - loss: 0.3714 - acc: 0.8579\n",
            "Epoch 162/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.3666 - acc: 0.8618\n",
            "Epoch 163/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.3662 - acc: 0.8610\n",
            "Epoch 164/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.3621 - acc: 0.8659\n",
            "Epoch 165/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.4031 - acc: 0.8388\n",
            "Epoch 166/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.3743 - acc: 0.8552\n",
            "Epoch 167/400\n",
            "10662/10662 [==============================] - 2s 154us/sample - loss: 0.3783 - acc: 0.8543\n",
            "Epoch 168/400\n",
            "10662/10662 [==============================] - 2s 154us/sample - loss: 0.3660 - acc: 0.8604\n",
            "Epoch 169/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.3586 - acc: 0.8678\n",
            "Epoch 170/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.3630 - acc: 0.8638\n",
            "Epoch 171/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.3548 - acc: 0.8680\n",
            "Epoch 172/400\n",
            "10662/10662 [==============================] - 2s 156us/sample - loss: 0.3507 - acc: 0.8708\n",
            "Epoch 173/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.3495 - acc: 0.8722\n",
            "Epoch 174/400\n",
            "10662/10662 [==============================] - 2s 154us/sample - loss: 0.3480 - acc: 0.8707\n",
            "Epoch 175/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.3424 - acc: 0.8790\n",
            "Epoch 176/400\n",
            "10662/10662 [==============================] - 2s 154us/sample - loss: 0.3445 - acc: 0.8761\n",
            "Epoch 177/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.4350 - acc: 0.8221\n",
            "Epoch 178/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.3468 - acc: 0.8750\n",
            "Epoch 179/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.3616 - acc: 0.8651\n",
            "Epoch 180/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.3607 - acc: 0.8629\n",
            "Epoch 181/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.3390 - acc: 0.8808\n",
            "Epoch 182/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.3327 - acc: 0.8844\n",
            "Epoch 183/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.3319 - acc: 0.8821\n",
            "Epoch 184/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.3265 - acc: 0.8864\n",
            "Epoch 185/400\n",
            "10662/10662 [==============================] - 2s 154us/sample - loss: 0.3440 - acc: 0.8750\n",
            "Epoch 186/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.3331 - acc: 0.8814\n",
            "Epoch 187/400\n",
            "10662/10662 [==============================] - 2s 154us/sample - loss: 0.3188 - acc: 0.8935\n",
            "Epoch 188/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.3705 - acc: 0.8576\n",
            "Epoch 189/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.3868 - acc: 0.8432\n",
            "Epoch 190/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.3955 - acc: 0.8389\n",
            "Epoch 191/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.3531 - acc: 0.8660\n",
            "Epoch 192/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.3455 - acc: 0.8749\n",
            "Epoch 193/400\n",
            "10662/10662 [==============================] - 2s 156us/sample - loss: 0.3396 - acc: 0.8768\n",
            "Epoch 194/400\n",
            "10662/10662 [==============================] - 2s 154us/sample - loss: 0.3152 - acc: 0.8949\n",
            "Epoch 195/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.3116 - acc: 0.8950\n",
            "Epoch 196/400\n",
            "10662/10662 [==============================] - 2s 156us/sample - loss: 0.3240 - acc: 0.8879\n",
            "Epoch 197/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.3071 - acc: 0.8992\n",
            "Epoch 198/400\n",
            "10662/10662 [==============================] - 2s 154us/sample - loss: 0.3041 - acc: 0.8997\n",
            "Epoch 199/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.3007 - acc: 0.9026\n",
            "Epoch 200/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.3027 - acc: 0.9009\n",
            "Epoch 201/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.3177 - acc: 0.8892\n",
            "Epoch 202/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.3723 - acc: 0.8560\n",
            "Epoch 203/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.3064 - acc: 0.8972\n",
            "Epoch 204/400\n",
            "10662/10662 [==============================] - 2s 154us/sample - loss: 0.3185 - acc: 0.8886\n",
            "Epoch 205/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.3228 - acc: 0.8860\n",
            "Epoch 206/400\n",
            "10662/10662 [==============================] - 2s 154us/sample - loss: 0.3241 - acc: 0.8866\n",
            "Epoch 207/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.3041 - acc: 0.8994\n",
            "Epoch 208/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.2933 - acc: 0.9075\n",
            "Epoch 209/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.2938 - acc: 0.9056\n",
            "Epoch 210/400\n",
            "10662/10662 [==============================] - 2s 154us/sample - loss: 0.2992 - acc: 0.9016\n",
            "Epoch 211/400\n",
            "10662/10662 [==============================] - 2s 154us/sample - loss: 0.2839 - acc: 0.9092\n",
            "Epoch 212/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.2763 - acc: 0.9158\n",
            "Epoch 213/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.2906 - acc: 0.9083\n",
            "Epoch 214/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.2769 - acc: 0.9157\n",
            "Epoch 215/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.2736 - acc: 0.9170\n",
            "Epoch 216/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.2784 - acc: 0.9141\n",
            "Epoch 217/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.2760 - acc: 0.9149\n",
            "Epoch 218/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.2635 - acc: 0.9205\n",
            "Epoch 219/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.3297 - acc: 0.8841\n",
            "Epoch 220/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.2931 - acc: 0.9036\n",
            "Epoch 221/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.3454 - acc: 0.8705\n",
            "Epoch 222/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.2988 - acc: 0.9006\n",
            "Epoch 223/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.3002 - acc: 0.9009\n",
            "Epoch 224/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.2898 - acc: 0.9079\n",
            "Epoch 225/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.3015 - acc: 0.9001\n",
            "Epoch 226/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.2771 - acc: 0.9142\n",
            "Epoch 227/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.2961 - acc: 0.9000\n",
            "Epoch 228/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.3041 - acc: 0.8958\n",
            "Epoch 229/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.2765 - acc: 0.9116\n",
            "Epoch 230/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.2646 - acc: 0.9195\n",
            "Epoch 231/400\n",
            "10662/10662 [==============================] - 2s 156us/sample - loss: 0.2598 - acc: 0.9221\n",
            "Epoch 232/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.2666 - acc: 0.9180\n",
            "Epoch 233/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.2555 - acc: 0.9255\n",
            "Epoch 234/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.2557 - acc: 0.9246\n",
            "Epoch 235/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.2584 - acc: 0.9236\n",
            "Epoch 236/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.2425 - acc: 0.9328\n",
            "Epoch 237/400\n",
            "10662/10662 [==============================] - 2s 154us/sample - loss: 0.2456 - acc: 0.9297\n",
            "Epoch 238/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.2469 - acc: 0.9288\n",
            "Epoch 239/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.2385 - acc: 0.9334\n",
            "Epoch 240/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.2384 - acc: 0.9331\n",
            "Epoch 241/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.2594 - acc: 0.9226\n",
            "Epoch 242/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.2420 - acc: 0.9318\n",
            "Epoch 243/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.2530 - acc: 0.9245\n",
            "Epoch 244/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.2481 - acc: 0.9282\n",
            "Epoch 245/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.2426 - acc: 0.9309\n",
            "Epoch 246/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.2438 - acc: 0.9295\n",
            "Epoch 247/400\n",
            "10662/10662 [==============================] - 2s 154us/sample - loss: 0.2575 - acc: 0.9204\n",
            "Epoch 248/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.2392 - acc: 0.9314\n",
            "Epoch 249/400\n",
            "10662/10662 [==============================] - 2s 154us/sample - loss: 0.2395 - acc: 0.9312\n",
            "Epoch 250/400\n",
            "10662/10662 [==============================] - 2s 154us/sample - loss: 0.2893 - acc: 0.9047\n",
            "Epoch 251/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.2561 - acc: 0.9222\n",
            "Epoch 252/400\n",
            "10662/10662 [==============================] - 2s 154us/sample - loss: 0.2727 - acc: 0.9132\n",
            "Epoch 253/400\n",
            "10662/10662 [==============================] - 2s 156us/sample - loss: 0.2708 - acc: 0.9147\n",
            "Epoch 254/400\n",
            "10662/10662 [==============================] - 2s 156us/sample - loss: 0.2373 - acc: 0.9342\n",
            "Epoch 255/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.2380 - acc: 0.9328\n",
            "Epoch 256/400\n",
            "10662/10662 [==============================] - 2s 156us/sample - loss: 0.2360 - acc: 0.9337\n",
            "Epoch 257/400\n",
            "10662/10662 [==============================] - 2s 156us/sample - loss: 0.2406 - acc: 0.9315\n",
            "Epoch 258/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.2260 - acc: 0.9395\n",
            "Epoch 259/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.2337 - acc: 0.9353\n",
            "Epoch 260/400\n",
            "10662/10662 [==============================] - 2s 156us/sample - loss: 0.2303 - acc: 0.9358\n",
            "Epoch 261/400\n",
            "10662/10662 [==============================] - 2s 157us/sample - loss: 0.2239 - acc: 0.9403\n",
            "Epoch 262/400\n",
            "10662/10662 [==============================] - 2s 156us/sample - loss: 0.2211 - acc: 0.9412\n",
            "Epoch 263/400\n",
            "10662/10662 [==============================] - 2s 156us/sample - loss: 0.2212 - acc: 0.9408\n",
            "Epoch 264/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.2172 - acc: 0.9426\n",
            "Epoch 265/400\n",
            "10662/10662 [==============================] - 2s 156us/sample - loss: 0.2145 - acc: 0.9443\n",
            "Epoch 266/400\n",
            "10662/10662 [==============================] - 2s 156us/sample - loss: 0.2177 - acc: 0.9428\n",
            "Epoch 267/400\n",
            "10662/10662 [==============================] - 2s 156us/sample - loss: 0.2156 - acc: 0.9431\n",
            "Epoch 268/400\n",
            "10662/10662 [==============================] - 2s 156us/sample - loss: 0.2105 - acc: 0.9462\n",
            "Epoch 269/400\n",
            "10662/10662 [==============================] - 2s 156us/sample - loss: 0.2130 - acc: 0.9453\n",
            "Epoch 270/400\n",
            "10662/10662 [==============================] - 2s 156us/sample - loss: 0.2118 - acc: 0.9446\n",
            "Epoch 271/400\n",
            "10662/10662 [==============================] - 2s 156us/sample - loss: 0.2246 - acc: 0.9375\n",
            "Epoch 272/400\n",
            "10662/10662 [==============================] - 2s 156us/sample - loss: 0.2681 - acc: 0.9156\n",
            "Epoch 273/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.2169 - acc: 0.9421\n",
            "Epoch 274/400\n",
            "10662/10662 [==============================] - 2s 156us/sample - loss: 0.2285 - acc: 0.9358\n",
            "Epoch 275/400\n",
            "10662/10662 [==============================] - 2s 156us/sample - loss: 0.2251 - acc: 0.9376\n",
            "Epoch 276/400\n",
            "10662/10662 [==============================] - 2s 156us/sample - loss: 0.2168 - acc: 0.9426\n",
            "Epoch 277/400\n",
            "10662/10662 [==============================] - 2s 157us/sample - loss: 0.2129 - acc: 0.9450\n",
            "Epoch 278/400\n",
            "10662/10662 [==============================] - 2s 156us/sample - loss: 0.2106 - acc: 0.9452\n",
            "Epoch 279/400\n",
            "10662/10662 [==============================] - 2s 156us/sample - loss: 0.2074 - acc: 0.9470\n",
            "Epoch 280/400\n",
            "10662/10662 [==============================] - 2s 156us/sample - loss: 0.2082 - acc: 0.9468\n",
            "Epoch 281/400\n",
            "10662/10662 [==============================] - 2s 157us/sample - loss: 0.2060 - acc: 0.9471\n",
            "Epoch 282/400\n",
            "10662/10662 [==============================] - 2s 156us/sample - loss: 0.2055 - acc: 0.9476\n",
            "Epoch 283/400\n",
            "10662/10662 [==============================] - 2s 156us/sample - loss: 0.2035 - acc: 0.9483\n",
            "Epoch 284/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.2078 - acc: 0.9464\n",
            "Epoch 285/400\n",
            "10662/10662 [==============================] - 2s 156us/sample - loss: 0.2075 - acc: 0.9459\n",
            "Epoch 286/400\n",
            "10662/10662 [==============================] - 2s 156us/sample - loss: 0.2073 - acc: 0.9464\n",
            "Epoch 287/400\n",
            "10662/10662 [==============================] - 2s 156us/sample - loss: 0.2494 - acc: 0.9250\n",
            "Epoch 288/400\n",
            "10662/10662 [==============================] - 2s 156us/sample - loss: 0.2259 - acc: 0.9369\n",
            "Epoch 289/400\n",
            "10662/10662 [==============================] - 2s 156us/sample - loss: 0.2574 - acc: 0.9210\n",
            "Epoch 290/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.2197 - acc: 0.9399\n",
            "Epoch 291/400\n",
            "10662/10662 [==============================] - 2s 156us/sample - loss: 0.2210 - acc: 0.9396\n",
            "Epoch 292/400\n",
            "10662/10662 [==============================] - 2s 156us/sample - loss: 0.2167 - acc: 0.9412\n",
            "Epoch 293/400\n",
            "10662/10662 [==============================] - 2s 156us/sample - loss: 0.2184 - acc: 0.9407\n",
            "Epoch 294/400\n",
            "10662/10662 [==============================] - 2s 156us/sample - loss: 0.2046 - acc: 0.9474\n",
            "Epoch 295/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.2067 - acc: 0.9466\n",
            "Epoch 296/400\n",
            "10662/10662 [==============================] - 2s 156us/sample - loss: 0.2046 - acc: 0.9476\n",
            "Epoch 297/400\n",
            "10662/10662 [==============================] - 2s 156us/sample - loss: 0.2001 - acc: 0.9501\n",
            "Epoch 298/400\n",
            "10662/10662 [==============================] - 2s 156us/sample - loss: 0.2013 - acc: 0.9489\n",
            "Epoch 299/400\n",
            "10662/10662 [==============================] - 2s 156us/sample - loss: 0.1997 - acc: 0.9494\n",
            "Epoch 300/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.1983 - acc: 0.9502\n",
            "Epoch 301/400\n",
            "10662/10662 [==============================] - 2s 156us/sample - loss: 0.1978 - acc: 0.9504\n",
            "Epoch 302/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.1990 - acc: 0.9501\n",
            "Epoch 303/400\n",
            "10662/10662 [==============================] - 2s 156us/sample - loss: 0.1970 - acc: 0.9508\n",
            "Epoch 304/400\n",
            "10662/10662 [==============================] - 2s 156us/sample - loss: 0.1970 - acc: 0.9509\n",
            "Epoch 305/400\n",
            "10662/10662 [==============================] - 2s 156us/sample - loss: 0.1962 - acc: 0.9509\n",
            "Epoch 306/400\n",
            "10662/10662 [==============================] - 2s 156us/sample - loss: 0.1973 - acc: 0.9504\n",
            "Epoch 307/400\n",
            "10662/10662 [==============================] - 2s 156us/sample - loss: 0.1957 - acc: 0.9513\n",
            "Epoch 308/400\n",
            "10662/10662 [==============================] - 2s 156us/sample - loss: 0.1958 - acc: 0.9512\n",
            "Epoch 309/400\n",
            "10662/10662 [==============================] - 2s 156us/sample - loss: 0.1954 - acc: 0.9511\n",
            "Epoch 310/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.1943 - acc: 0.9517\n",
            "Epoch 311/400\n",
            "10662/10662 [==============================] - 2s 156us/sample - loss: 0.1949 - acc: 0.9515\n",
            "Epoch 312/400\n",
            "10662/10662 [==============================] - 2s 156us/sample - loss: 0.1938 - acc: 0.9519\n",
            "Epoch 313/400\n",
            "10662/10662 [==============================] - 2s 156us/sample - loss: 0.1941 - acc: 0.9515\n",
            "Epoch 314/400\n",
            "10662/10662 [==============================] - 2s 156us/sample - loss: 0.1936 - acc: 0.9519\n",
            "Epoch 315/400\n",
            "10662/10662 [==============================] - 2s 156us/sample - loss: 0.1937 - acc: 0.9517\n",
            "Epoch 316/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.1937 - acc: 0.9518\n",
            "Epoch 317/400\n",
            "10662/10662 [==============================] - 2s 156us/sample - loss: 0.1935 - acc: 0.9519\n",
            "Epoch 318/400\n",
            "10662/10662 [==============================] - 2s 156us/sample - loss: 0.1935 - acc: 0.9518\n",
            "Epoch 319/400\n",
            "10662/10662 [==============================] - 2s 156us/sample - loss: 0.1930 - acc: 0.9520\n",
            "Epoch 320/400\n",
            "10662/10662 [==============================] - 2s 156us/sample - loss: 0.1939 - acc: 0.9516\n",
            "Epoch 321/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.1933 - acc: 0.9518\n",
            "Epoch 322/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.1942 - acc: 0.9513\n",
            "Epoch 323/400\n",
            "10662/10662 [==============================] - 2s 156us/sample - loss: 0.1937 - acc: 0.9516\n",
            "Epoch 324/400\n",
            "10662/10662 [==============================] - 2s 156us/sample - loss: 0.1931 - acc: 0.9516\n",
            "Epoch 325/400\n",
            "10662/10662 [==============================] - 2s 156us/sample - loss: 0.1930 - acc: 0.9518\n",
            "Epoch 326/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.1926 - acc: 0.9520\n",
            "Epoch 327/400\n",
            "10662/10662 [==============================] - 2s 156us/sample - loss: 0.1938 - acc: 0.9515\n",
            "Epoch 328/400\n",
            "10662/10662 [==============================] - 2s 156us/sample - loss: 0.1945 - acc: 0.9509\n",
            "Epoch 329/400\n",
            "10662/10662 [==============================] - 2s 157us/sample - loss: 0.1956 - acc: 0.9506\n",
            "Epoch 330/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.1946 - acc: 0.9508\n",
            "Epoch 331/400\n",
            "10662/10662 [==============================] - 2s 157us/sample - loss: 0.1964 - acc: 0.9503\n",
            "Epoch 332/400\n",
            "10662/10662 [==============================] - 2s 156us/sample - loss: 0.1979 - acc: 0.9496\n",
            "Epoch 333/400\n",
            "10662/10662 [==============================] - 2s 156us/sample - loss: 0.2056 - acc: 0.9462\n",
            "Epoch 334/400\n",
            "10662/10662 [==============================] - 2s 156us/sample - loss: 0.2064 - acc: 0.9457\n",
            "Epoch 335/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.2010 - acc: 0.9479\n",
            "Epoch 336/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.2047 - acc: 0.9461\n",
            "Epoch 337/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.2030 - acc: 0.9467\n",
            "Epoch 338/400\n",
            "10662/10662 [==============================] - 2s 156us/sample - loss: 0.2028 - acc: 0.9468\n",
            "Epoch 339/400\n",
            "10662/10662 [==============================] - 2s 156us/sample - loss: 0.1977 - acc: 0.9494\n",
            "Epoch 340/400\n",
            "10662/10662 [==============================] - 2s 156us/sample - loss: 0.2060 - acc: 0.9451\n",
            "Epoch 341/400\n",
            "10662/10662 [==============================] - 2s 156us/sample - loss: 0.2189 - acc: 0.9389\n",
            "Epoch 342/400\n",
            "10662/10662 [==============================] - 2s 156us/sample - loss: 0.2157 - acc: 0.9417\n",
            "Epoch 343/400\n",
            "10662/10662 [==============================] - 2s 156us/sample - loss: 0.2329 - acc: 0.9316\n",
            "Epoch 344/400\n",
            "10662/10662 [==============================] - 2s 156us/sample - loss: 0.2594 - acc: 0.9199\n",
            "Epoch 345/400\n",
            "10662/10662 [==============================] - 2s 156us/sample - loss: 0.2276 - acc: 0.9356\n",
            "Epoch 346/400\n",
            "10662/10662 [==============================] - 2s 156us/sample - loss: 0.3016 - acc: 0.9002\n",
            "Epoch 347/400\n",
            "10662/10662 [==============================] - 2s 156us/sample - loss: 0.2908 - acc: 0.9056\n",
            "Epoch 348/400\n",
            "10662/10662 [==============================] - 2s 156us/sample - loss: 0.2914 - acc: 0.9011\n",
            "Epoch 349/400\n",
            "10662/10662 [==============================] - 2s 156us/sample - loss: 0.2695 - acc: 0.9113\n",
            "Epoch 350/400\n",
            "10662/10662 [==============================] - 2s 156us/sample - loss: 0.2771 - acc: 0.9057\n",
            "Epoch 351/400\n",
            "10662/10662 [==============================] - 2s 156us/sample - loss: 0.2485 - acc: 0.9234\n",
            "Epoch 352/400\n",
            "10662/10662 [==============================] - 2s 156us/sample - loss: 0.2371 - acc: 0.9299\n",
            "Epoch 353/400\n",
            "10662/10662 [==============================] - 2s 156us/sample - loss: 0.2413 - acc: 0.9281\n",
            "Epoch 354/400\n",
            "10662/10662 [==============================] - 2s 156us/sample - loss: 0.2240 - acc: 0.9363\n",
            "Epoch 355/400\n",
            "10662/10662 [==============================] - 2s 156us/sample - loss: 0.2118 - acc: 0.9430\n",
            "Epoch 356/400\n",
            "10662/10662 [==============================] - 2s 156us/sample - loss: 0.2098 - acc: 0.9444\n",
            "Epoch 357/400\n",
            "10662/10662 [==============================] - 2s 156us/sample - loss: 0.2026 - acc: 0.9481\n",
            "Epoch 358/400\n",
            "10662/10662 [==============================] - 2s 156us/sample - loss: 0.1992 - acc: 0.9485\n",
            "Epoch 359/400\n",
            "10662/10662 [==============================] - 2s 156us/sample - loss: 0.1994 - acc: 0.9485\n",
            "Epoch 360/400\n",
            "10662/10662 [==============================] - 2s 156us/sample - loss: 0.1987 - acc: 0.9480\n",
            "Epoch 361/400\n",
            "10662/10662 [==============================] - 2s 156us/sample - loss: 0.1985 - acc: 0.9478\n",
            "Epoch 362/400\n",
            "10662/10662 [==============================] - 2s 156us/sample - loss: 0.1975 - acc: 0.9486\n",
            "Epoch 363/400\n",
            "10662/10662 [==============================] - 2s 156us/sample - loss: 0.1924 - acc: 0.9517\n",
            "Epoch 364/400\n",
            "10662/10662 [==============================] - 2s 156us/sample - loss: 0.1951 - acc: 0.9500\n",
            "Epoch 365/400\n",
            "10662/10662 [==============================] - 2s 156us/sample - loss: 0.1906 - acc: 0.9521\n",
            "Epoch 366/400\n",
            "10662/10662 [==============================] - 2s 156us/sample - loss: 0.1904 - acc: 0.9520\n",
            "Epoch 367/400\n",
            "10662/10662 [==============================] - 2s 156us/sample - loss: 0.1902 - acc: 0.9523\n",
            "Epoch 368/400\n",
            "10662/10662 [==============================] - 2s 156us/sample - loss: 0.1892 - acc: 0.9524\n",
            "Epoch 369/400\n",
            "10662/10662 [==============================] - 2s 156us/sample - loss: 0.1880 - acc: 0.9531\n",
            "Epoch 370/400\n",
            "10662/10662 [==============================] - 2s 156us/sample - loss: 0.1886 - acc: 0.9531\n",
            "Epoch 371/400\n",
            "10662/10662 [==============================] - 2s 157us/sample - loss: 0.1878 - acc: 0.9532\n",
            "Epoch 372/400\n",
            "10662/10662 [==============================] - 2s 156us/sample - loss: 0.1867 - acc: 0.9537\n",
            "Epoch 373/400\n",
            "10662/10662 [==============================] - 2s 156us/sample - loss: 0.1864 - acc: 0.9539\n",
            "Epoch 374/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.1859 - acc: 0.9540\n",
            "Epoch 375/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.1859 - acc: 0.9540\n",
            "Epoch 376/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.1862 - acc: 0.9539\n",
            "Epoch 377/400\n",
            "10662/10662 [==============================] - 2s 156us/sample - loss: 0.1856 - acc: 0.9541\n",
            "Epoch 378/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.1852 - acc: 0.9542\n",
            "Epoch 379/400\n",
            "10662/10662 [==============================] - 2s 156us/sample - loss: 0.1853 - acc: 0.9540\n",
            "Epoch 380/400\n",
            "10662/10662 [==============================] - 2s 156us/sample - loss: 0.1857 - acc: 0.9538\n",
            "Epoch 381/400\n",
            "10662/10662 [==============================] - 2s 156us/sample - loss: 0.1847 - acc: 0.9543\n",
            "Epoch 382/400\n",
            "10662/10662 [==============================] - 2s 156us/sample - loss: 0.1848 - acc: 0.9542\n",
            "Epoch 383/400\n",
            "10662/10662 [==============================] - 2s 156us/sample - loss: 0.1844 - acc: 0.9545\n",
            "Epoch 384/400\n",
            "10662/10662 [==============================] - 2s 156us/sample - loss: 0.1843 - acc: 0.9544\n",
            "Epoch 385/400\n",
            "10662/10662 [==============================] - 2s 156us/sample - loss: 0.1844 - acc: 0.9545\n",
            "Epoch 386/400\n",
            "10662/10662 [==============================] - 2s 156us/sample - loss: 0.1841 - acc: 0.9545\n",
            "Epoch 387/400\n",
            "10662/10662 [==============================] - 2s 156us/sample - loss: 0.1840 - acc: 0.9546\n",
            "Epoch 388/400\n",
            "10662/10662 [==============================] - 2s 155us/sample - loss: 0.1840 - acc: 0.9545\n",
            "Epoch 389/400\n",
            "10662/10662 [==============================] - 2s 157us/sample - loss: 0.1838 - acc: 0.9546\n",
            "Epoch 390/400\n",
            "10662/10662 [==============================] - 2s 156us/sample - loss: 0.1838 - acc: 0.9546\n",
            "Epoch 391/400\n",
            "10662/10662 [==============================] - 2s 156us/sample - loss: 0.1838 - acc: 0.9545\n",
            "Epoch 392/400\n",
            "10662/10662 [==============================] - 2s 156us/sample - loss: 0.1837 - acc: 0.9546\n",
            "Epoch 393/400\n",
            "10662/10662 [==============================] - 2s 156us/sample - loss: 0.1836 - acc: 0.9546\n",
            "Epoch 394/400\n",
            "10662/10662 [==============================] - 2s 156us/sample - loss: 0.1835 - acc: 0.9546\n",
            "Epoch 395/400\n",
            "10662/10662 [==============================] - 2s 157us/sample - loss: 0.1835 - acc: 0.9546\n",
            "Epoch 396/400\n",
            "10662/10662 [==============================] - 2s 156us/sample - loss: 0.1834 - acc: 0.9546\n",
            "Epoch 397/400\n",
            "10662/10662 [==============================] - 2s 156us/sample - loss: 0.1833 - acc: 0.9547\n",
            "Epoch 398/400\n",
            "10662/10662 [==============================] - 2s 156us/sample - loss: 0.1833 - acc: 0.9547\n",
            "Epoch 399/400\n",
            "10662/10662 [==============================] - 2s 156us/sample - loss: 0.1833 - acc: 0.9547\n",
            "Epoch 400/400\n",
            "10662/10662 [==============================] - 2s 156us/sample - loss: 0.1832 - acc: 0.9547\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f98177b9f28>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n91ixcgjwD9e",
        "colab_type": "code",
        "outputId": "10578aaf-71dd-4de2-8a72-835fa19d9cf7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        }
      },
      "source": [
        "while True:\n",
        "    statement = input(\"Enter statement:\")\n",
        "    if statement == \"\":\n",
        "        break\n",
        "    statement = statement.lower()\n",
        "    statement = \"\".join([' ' if y in string.punctuation else y for y in list(statement)])\n",
        "    statement = re.split('\\s+', statement)\n",
        "    statement = [word for word in statement if word in word_to_vec_map]\n",
        "    statement = [word for word in statement] + ['' for y in range(max_len - len(statement))]\n",
        "    statement = [word_to_index_map[word] for word in statement]\n",
        "    predicted_label = model.predict(np.array(statement).reshape(1, max_len))\n",
        "    if predicted_label >= 0.5:\n",
        "        print(\"Positive\")\n",
        "    else:\n",
        "        print(\"Negative\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter statement:i loved it\n",
            "Positive\n",
            "Enter statement:not worth the money\n",
            "Positive\n",
            "Enter statement:good film\n",
            "Positive\n",
            "Enter statement:i did not like it at all\n",
            "Negative\n",
            "Enter statement:brilliant acting\n",
            "Positive\n",
            "Enter statement:good direction\n",
            "Positive\n",
            "Enter statement:bad cinematography\n",
            "Negative\n",
            "Enter statement:good watch\n",
            "Positive\n",
            "Enter statement:worth the money\n",
            "Positive\n",
            "Enter statement:i hate this film\n",
            "Negative\n",
            "Enter statement:\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}